{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Model Deployment\n",
    "\n",
    "This notebook demonstrates how to deploy a trained XGBoost model using AWS SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install seaborn\n",
    "%reset -f\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from time import gmtime, strftime\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "boto3_session = boto3.Session()\n",
    "sagemaker_client = boto3_session.client('sagemaker')\n",
    "sagemaker_runtime = boto3_session.client('sagemaker-runtime')\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Check if S3 Bucket and Test Data File Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if S3 bucket exists\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "def check_s3_bucket(bucket_name: str) -> bool:\n",
    "    \"\"\"Check if the S3 bucket exists and is accessible.\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): Name of the S3 bucket.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if bucket exists and accessible, False otherwise.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        s3.head_bucket(Bucket=bucket_name)\n",
    "        return True\n",
    "    except ClientError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def check_s3_object(bucket_name: str, key: str) -> bool:\n",
    "    \"\"\"Check whether an S3 object exists and is accessible.\"\"\"\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=bucket_name, Key=key)\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        error_code = e.response[\"Error\"][\"Code\"]\n",
    "        if error_code in (\"404\", \"NoSuchKey\"):\n",
    "            return False\n",
    "        elif error_code == \"403\":\n",
    "            raise PermissionError(f\"Access denied for s3://{bucket_name}/{key}\")\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "def get_user_input(prompt: str) -> str:\n",
    "    \"\"\"Prompt user for input and ensure it's not empty.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Prompt text to display.\n",
    "    \n",
    "    Returns:\n",
    "        str: User input.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        value = input(prompt).strip()\n",
    "        if value:\n",
    "            return value\n",
    "        print(\"Input cannot be empty. Please try again.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Interactive inputs\n",
    "# -------------------------\n",
    "bucket_name = get_user_input(\"Enter the S3 bucket name: \")\n",
    "test_data_filepath = get_user_input(\"Enter 'test' data file path which contains test data: \")\n",
    "\n",
    "# -------------------------\n",
    "# Check bucket existence\n",
    "# -------------------------\n",
    "if not check_s3_bucket(bucket_name):\n",
    "    raise ValueError(f\"S3 Bucket '{bucket_name}' does not exist or you don't have access!\")\n",
    "\n",
    "# -------------------------\n",
    "# Check 'test' data file existence\n",
    "# -------------------------\n",
    "if not check_s3_object(bucket_name, test_data_filepath):\n",
    "    raise ValueError(f\"'test' data file '{test_data_filepath}' does not exist or you don't have access!\")\n",
    "\n",
    "print(f\"S3 Bucket '{bucket_name}' exists ✅\")\n",
    "print(f\"'test' data file '{test_data_filepath}' exists ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Download Test Dataset from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(bucket_name, test_data_filepath, 'adult_data_processed_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Remove Labels from the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"adult_data_processed_test.csv\"\n",
    "OUTPUT_FILE = \"adult_data_processed_test_no_target.csv\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# Extract target column (labels)\n",
    "df_labels = df.iloc[:, 0]\n",
    "\n",
    "# Remove target column from dataframe\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "# Save remaining features to new CSV (no index, no header)\n",
    "df.to_csv(OUTPUT_FILE, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Setup the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Constants\n",
    "# -----------------------------\n",
    "FRAMEWORK_NAME = \"xgboost\"\n",
    "FRAMEWORK_VERSION = \"1.7-1\"\n",
    "\n",
    "# -----------------------------\n",
    "# Generate a unique run name\n",
    "# -----------------------------\n",
    "run_timestamp = strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f\"vijay-xgboost-income-model-{run_timestamp}\"\n",
    "\n",
    "# -----------------------------\n",
    "# Model artifact location\n",
    "# -----------------------------\n",
    "MODEL_DATA_S3_PATH = f\"scripts/data/models/model.tar.gz\"\n",
    "MODEL_DATA_S3_URL = f\"s3://{bucket_name}/scripts/data/models/model.tar.gz\"\n",
    "\n",
    "# -------------------------\n",
    "# Check Model file existence\n",
    "# -------------------------\n",
    "if not check_s3_object(bucket_name, MODEL_DATA_S3_PATH):\n",
    "    raise ValueError(f\"Model data file '{MODEL_DATA_S3_PATH}' does not exist or you don't have access!\")\n",
    "\n",
    "print(f\"Model file '{MODEL_DATA_S3_PATH}' exists ✅\")\n",
    "\n",
    "# -----------------------------\n",
    "# Retrieve XGBoost container URI\n",
    "# -----------------------------\n",
    "container_uri = image_uris.retrieve(\n",
    "    framework=FRAMEWORK_NAME,\n",
    "    region=region,\n",
    "    version=FRAMEWORK_VERSION\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Create the model in SageMaker\n",
    "# -----------------------------\n",
    "income_model = sagemaker_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": container_uri,\n",
    "        \"ModelDataUrl\": MODEL_DATA_S3_URL,\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Created SageMaker model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Configure an Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date = strftime(\"%Y%m%d-%H%M%S\")\n",
    "ENDPOINT_CONFIG_NAME = f\"vijay-income-model-real-time-endpoint-{create_date}\"\n",
    "INSTANCE_TYPE = \"ml.m5.xlarge\"\n",
    "INITIAL_SAMPLING_PERCENTAGE = 25  # The percentage of requests SageMaker AI will capture. A lower value is recommended for Endpoints with high traffic.\n",
    "CAPTURE_MODES = [\"Input\", \"Output\"]\n",
    "DATA_CAPTURE_S3_URI = f\"s3://{bucket_name}/data-capture\"\n",
    "\n",
    "# -----------------------------\n",
    "# Create endpoint config\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DataCaptureConfig.html\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ProductionVariant.html\n",
    "# -----------------------------\n",
    "# DataCaptureConfig is a feature of SageMaker endpoints that allows you to automatically record inference requests and responses and store them in S3.\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=ENDPOINT_CONFIG_NAME,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"VijayTestModel1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": INSTANCE_TYPE,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "        }\n",
    "    ],\n",
    "    DataCaptureConfig={\n",
    "        'EnableCapture': True,  # Whether data should be captured or not.\n",
    "        'InitialSamplingPercentage': INITIAL_SAMPLING_PERCENTAGE,\n",
    "        'DestinationS3Uri': f's3://{bucket_name}/data-capture',\n",
    "        'CaptureOptions': [{\"CaptureMode\": capture_mode} for capture_mode in CAPTURE_MODES]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Create the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique endpoint name based on the endpoint configuration\n",
    "endpoint_name = f\"{ENDPOINT_CONFIG_NAME}-endpoint\"\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=ENDPOINT_CONFIG_NAME,\n",
    ")\n",
    "\n",
    "print(f\"Endpoint creation started: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Check Status of Endpoint Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response.get(\"EndpointStatus\")\n",
    "print(status)\n",
    "\n",
    "# Poll endpoint status until it is created\n",
    "while status == \"Creating\":\n",
    "    print(\"Waiting for endpoint creation...\")\n",
    "    time.sleep(15)\n",
    "    response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = response.get(\"EndpointStatus\")\n",
    "\n",
    "# Handle failure\n",
    "if status != \"InService\":\n",
    "    failure_reason = response.get(\"FailureReason\", \"Unknown reason\")\n",
    "    endpoint_arn = create_endpoint_response.get(\"EndpointArn\", \"Unknown ARN\")\n",
    "    print(f\"Failed to create endpoint. Status: {status}\")\n",
    "    print(f\"Response: {response}\")\n",
    "    raise SystemExit(\n",
    "        f\"Failed to create endpoint {endpoint_arn}. \"\n",
    "        f\"Status: {status}. Reason: {failure_reason}\"\n",
    "    )\n",
    "\n",
    "# Success message\n",
    "endpoint_arn = create_endpoint_response.get(\"EndpointArn\", \"Unknown ARN\")\n",
    "print(f\"Endpoint {endpoint_arn} successfully created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the cutoff value for binary classification\n",
    "CUTOFF_VALUE = 0.5\n",
    "\n",
    "def convert_probability_to_binary(probability: float) -> int:\n",
    "    \"\"\"Convert probability to binary class using cutoff value.\"\"\"\n",
    "    return 1 if probability >= CUTOFF_VALUE else 0\n",
    "\n",
    "\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with open(\"adult_data_processed_test_no_target.csv\", \"r\") as f:\n",
    "    for row in f:\n",
    "        payload = row.strip()\n",
    "\n",
    "        response = sm_runtime.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            ContentType=\"text/csv\",\n",
    "            Body=payload\n",
    "        )\n",
    "\n",
    "        pred_probability = float(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "        predictions.append(convert_probability_to_binary(pred_probability))\n",
    "\n",
    "# Convert predictions list to numpy array\n",
    "pred_np = np.array(predictions, dtype=int)\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
